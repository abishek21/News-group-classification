{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as skd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['alt.atheism','soc.religion.christian','comp.graphics','sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train=skd.load_files('D:\\\\RESEARCH PROJECT\\\\text classification\\\\20news-bydate-train',categories=categories,encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test=skd.load_files('D:\\\\RESEARCH PROJECT\\\\text classification\\\\20news-bydate-test',categories=categories,encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.DataFrame(news_train.data,columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['categories']=news_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>From: ib@ivan.asd.sgi.com (Ivan Bach)\\nSubject...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>From: topcat!tom@tredysvr.tredydev.unisys.com ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>From: sean@whiting.mcs.com (Sean Gum)\\nSubject...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>From: dingebre@imp.sim.es.com (David Ingebrets...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>From: Nigel@dataman.demon.co.uk (Nigel Ballard...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  categories\n",
       "2252  From: ib@ivan.asd.sgi.com (Ivan Bach)\\nSubject...           1\n",
       "2253  From: topcat!tom@tredysvr.tredydev.unisys.com ...           3\n",
       "2254  From: sean@whiting.mcs.com (Sean Gum)\\nSubject...           1\n",
       "2255  From: dingebre@imp.sim.es.com (David Ingebrets...           1\n",
       "2256  From: Nigel@dataman.demon.co.uk (Nigel Ballard...           2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame(news_test.data,columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['categories']=news_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>From: dh@fncrd6.fnal.gov (don husby)\\nSubject:...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>From: russ@pmafire.inel.gov (Russ Brown)\\nSubj...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>From: mdw33310@uxa.cso.uiuc.edu (Michael D. Wa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>From: fishkin@parc.xerox.com (Ken Fishkin)\\nSu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>From: vicente@cenaath.cena.dgac.fr (Martin VIC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  categories\n",
       "1497  From: dh@fncrd6.fnal.gov (don husby)\\nSubject:...           2\n",
       "1498  From: russ@pmafire.inel.gov (Russ Brown)\\nSubj...           2\n",
       "1499  From: mdw33310@uxa.cso.uiuc.edu (Michael D. Wa...           3\n",
       "1500  From: fishkin@parc.xerox.com (Ken Fishkin)\\nSu...           1\n",
       "1501  From: vicente@cenaath.cena.dgac.fr (Martin VIC...           1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [train,test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>From: dh@fncrd6.fnal.gov (don husby)\\nSubject:...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>From: russ@pmafire.inel.gov (Russ Brown)\\nSubj...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>From: mdw33310@uxa.cso.uiuc.edu (Michael D. Wa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>From: fishkin@parc.xerox.com (Ken Fishkin)\\nSu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>From: vicente@cenaath.cena.dgac.fr (Martin VIC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  categories\n",
       "1497  From: dh@fncrd6.fnal.gov (don husby)\\nSubject:...           2\n",
       "1498  From: russ@pmafire.inel.gov (Russ Brown)\\nSubj...           2\n",
       "1499  From: mdw33310@uxa.cso.uiuc.edu (Michael D. Wa...           3\n",
       "1500  From: fishkin@parc.xerox.com (Ken Fishkin)\\nSu...           1\n",
       "1501  From: vicente@cenaath.cena.dgac.fr (Martin VIC...           1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(gensim.models.doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['From:', 'dpc47852@uxa.cso.uiuc.edu', '(Daniel', 'Paul', 'Checkman)', 'Subject:', 'Re:', 'Is', 'MSG', 'sensitivity', 'superstition?', 'Article-I.D.:', 'news.C5wI4F.Dt', 'Organization:', 'University', 'of', 'Illinois', 'at', 'Urbana', 'Lines:', '22', 'bruce@Data-IO.COM', '(Bruce', 'Reynolds)', 'writes:', '>Anecedotal', 'evidence', 'is', 'worthless.', 'Even', 'doctors', 'who', 'have', 'been', 'using', 'a', 'drug', '>or', 'treatment', 'for', 'years,', 'and', 'who', 'swear', 'it', 'is', 'effective,', 'are', 'often', 'suprised', '>at', 'the', 'results', 'of', 'clinical', 'trials.', 'Whether', 'or', 'not', 'MSG', 'causes', 'describable,', '>reportable,', 'documentable', 'symptoms', 'should', 'be', 'pretty', 'simple', 'to', 'discover.', 'I', 'tend', 'to', 'disagree-', 'I', 'think', 'anecdotal', 'evidence,', 'provided', 'there', 'is', 'a', 'lot', 'of', 'it,', 'and', 'it', 'is', 'fairly', 'consistent,', 'will', 'is', 'very', 'important.', 'First,', 'it', 'points', 'to', 'the', 'necessity', 'of', 'doing', 'a', 'study,', 'and', 'second,', 'it', 'at', 'least', 'says', 'that', 'the', 'effects', 'are', 'all', 'psychological', '(or', 'possibly', 'allergy', 'in', 'this', 'case).', 'As', \"I've\", 'pointed', 'out', 'before,', 'pyschological', 'effects', 'are', 'no', 'less', 'real', 'than', 'other', 'effects.', 'One', \"person's\", '\"make-believe\"', 'can', 'easily', 'be', 'another', \"person's\", 'reality.', 'Using', 'psychadelic', 'drugs', 'in', 'a', 'bizarre', 'and', 'twisted', 'example,', 'the', 'hallucinations', 'one', 'person', 'experiences', 'on', 'an', 'acid', 'trip', 'cannot', 'be', 'guaranteed', 'to', 'another', 'person', 'on', 'an', 'acid', 'trip-', 'there', 'is', 'no', 'clinical', 'evidence', 'that', 'those', 'effects', 'are', 'always', 'going', 'to', 'happen.', 'Anyhow,', 'that', 'was', 'a', 'pretty', 'lame', 'example,', 'but', 'hopefully', 'I', 'made', 'my', 'point-', \"it's\", 'all', 'a', 'matter', 'of', 'perception,', 'and', 'as', 'long', 'as', 'someone', 'ingesting', 'MSG', 'perceives', 'it', 'as', 'causing', 'bad', 'effects,', 'then', 's/he', 'can', 'definitely', 'experience', 'those', 'affects.', 'On', 'the', 'other', 'hand,', 'it', 'could', 'just', 'be', 'an', 'allergy', 'to', 'the', 'food', \"it's\", 'in,', 'or', 'something.', 'Still,', 'anecdotal', 'evidence', 'is', 'not', 'worthless-', \"it's\", 'the', 'stuff', 'that', 'leads', 'to', 'the', 'study', 'being', 'done.', '-Dan'], tags=['Train_0']),\n",
       " TaggedDocument(words=['From:', 'yoo@engr.ucf.edu', '(Hoi', 'Yoo)', 'Subject:', 'looking', 'for', 'USA', 'map', 'Organization:', 'engineering,', 'University', 'of', 'Central', 'Florida,', 'Orlando', 'Lines:', '11', 'Does', 'anyone', 'out', 'there', 'have', 'or', 'know', 'of,', 'line', 'drawing', 'USA', 'map?', 'Thanks', 'very', 'much', 'in', 'advance,', 'Hoi', 'yoo@engr.ucf.edu'], tags=['Train_1'])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction---- Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3759/3759 [00:00<00:00, 1202714.83it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3759/3759 [00:00<00:00, 5130617.88it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1255885.67it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1248427.33it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1266478.33it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 3882390.73it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1267496.48it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1239008.94it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1852689.63it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1927667.04it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1883453.44it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 942233.24it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1271072.94it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1428114.92it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 4400331.77it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1263130.01it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1432787.05it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 3903537.69it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 945397.18it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1931918.73it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1876057.68it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 2081646.26it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1535338.27it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1985941.40it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 4964228.19it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1807864.78it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1855742.55it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 942008.05it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1444469.88it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 2223123.06it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1575536.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abishek\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\abishek\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=1, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, news_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abishek\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\abishek\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg = logreg.fit(train_vectors_dbow, news_train.target)\n",
    "y_pred = logreg.predict(test_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8115845539280959\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.78      0.74      0.76       319\n",
      "soc.religion.christian       0.82      0.87      0.84       389\n",
      "         comp.graphics       0.84      0.81      0.82       396\n",
      "               sci.med       0.80      0.81      0.81       398\n",
      "\n",
      "              accuracy                           0.81      1502\n",
      "             macro avg       0.81      0.81      0.81      1502\n",
      "          weighted avg       0.81      0.81      0.81      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, news_test.target))\n",
    "print(classification_report(news_test.target, y_pred,target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(train_vectors_dbow, news_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7649800266311585\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.68      0.65      0.66       319\n",
      "soc.religion.christian       0.81      0.84      0.83       389\n",
      "         comp.graphics       0.83      0.75      0.79       396\n",
      "               sci.med       0.73      0.80      0.76       398\n",
      "\n",
      "              accuracy                           0.76      1502\n",
      "             macro avg       0.76      0.76      0.76      1502\n",
      "          weighted avg       0.77      0.76      0.76      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, news_test.target))\n",
    "print(classification_report(news_test.target, y_pred,target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# removing noise to check if accuracy can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-670d33d17503>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "all_data = all_data[pd.notnull(all_data['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752658"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abishek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "###cleaning the text\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    ##text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['post'] = train['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374715"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['post'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: dpc47852@uxa.cso.uiuc.edu (Daniel Paul C...</td>\n",
       "      <td>2</td>\n",
       "      <td>dpc47852 uxacsouiucedu daniel paul checkman su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: yoo@engr.ucf.edu (Hoi Yoo)\\nSubject: loo...</td>\n",
       "      <td>1</td>\n",
       "      <td>yoo engrucfedu hoi yoo subject looking usa map...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: fernandeza@merrimack.edu\\nSubject: Re: T...</td>\n",
       "      <td>3</td>\n",
       "      <td>fernandeza merrimackedusubject arrogance chris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: mcelwre@cnsvax.uwec.edu\\nSubject: NATURA...</td>\n",
       "      <td>2</td>\n",
       "      <td>mcelwre cnsvaxuwecedusubject natural anticance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
       "      <td>0</td>\n",
       "      <td>mathew mathew mantiscouksubject inimitable rus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  categories  \\\n",
       "0  From: dpc47852@uxa.cso.uiuc.edu (Daniel Paul C...           2   \n",
       "1  From: yoo@engr.ucf.edu (Hoi Yoo)\\nSubject: loo...           1   \n",
       "2  From: fernandeza@merrimack.edu\\nSubject: Re: T...           3   \n",
       "3  From: mcelwre@cnsvax.uwec.edu\\nSubject: NATURA...           2   \n",
       "4  From: mathew <mathew@mantis.co.uk>\\nSubject: R...           0   \n",
       "\n",
       "                                                post  \n",
       "0  dpc47852 uxacsouiucedu daniel paul checkman su...  \n",
       "1  yoo engrucfedu hoi yoo subject looking usa map...  \n",
       "2  fernandeza merrimackedusubject arrogance chris...  \n",
       "3  mcelwre cnsvaxuwecedusubject natural anticance...  \n",
       "4  mathew mathew mantiscouksubject inimitable rus...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570522"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['post'] = test['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281893"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['post'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=train['post']\n",
    "X_test1=test['post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = label_sentences(X_train1, 'Train')\n",
    "X_test1 = label_sentences(X_test1, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data1 = X_train1 + X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['From:', 'dpc47852@uxa.cso.uiuc.edu', '(Daniel', 'Paul', 'Checkman)', 'Subject:', 'Re:', 'Is', 'MSG', 'sensitivity', 'superstition?', 'Article-I.D.:', 'news.C5wI4F.Dt', 'Organization:', 'University', 'of', 'Illinois', 'at', 'Urbana', 'Lines:', '22', 'bruce@Data-IO.COM', '(Bruce', 'Reynolds)', 'writes:', '>Anecedotal', 'evidence', 'is', 'worthless.', 'Even', 'doctors', 'who', 'have', 'been', 'using', 'a', 'drug', '>or', 'treatment', 'for', 'years,', 'and', 'who', 'swear', 'it', 'is', 'effective,', 'are', 'often', 'suprised', '>at', 'the', 'results', 'of', 'clinical', 'trials.', 'Whether', 'or', 'not', 'MSG', 'causes', 'describable,', '>reportable,', 'documentable', 'symptoms', 'should', 'be', 'pretty', 'simple', 'to', 'discover.', 'I', 'tend', 'to', 'disagree-', 'I', 'think', 'anecdotal', 'evidence,', 'provided', 'there', 'is', 'a', 'lot', 'of', 'it,', 'and', 'it', 'is', 'fairly', 'consistent,', 'will', 'is', 'very', 'important.', 'First,', 'it', 'points', 'to', 'the', 'necessity', 'of', 'doing', 'a', 'study,', 'and', 'second,', 'it', 'at', 'least', 'says', 'that', 'the', 'effects', 'are', 'all', 'psychological', '(or', 'possibly', 'allergy', 'in', 'this', 'case).', 'As', \"I've\", 'pointed', 'out', 'before,', 'pyschological', 'effects', 'are', 'no', 'less', 'real', 'than', 'other', 'effects.', 'One', \"person's\", '\"make-believe\"', 'can', 'easily', 'be', 'another', \"person's\", 'reality.', 'Using', 'psychadelic', 'drugs', 'in', 'a', 'bizarre', 'and', 'twisted', 'example,', 'the', 'hallucinations', 'one', 'person', 'experiences', 'on', 'an', 'acid', 'trip', 'cannot', 'be', 'guaranteed', 'to', 'another', 'person', 'on', 'an', 'acid', 'trip-', 'there', 'is', 'no', 'clinical', 'evidence', 'that', 'those', 'effects', 'are', 'always', 'going', 'to', 'happen.', 'Anyhow,', 'that', 'was', 'a', 'pretty', 'lame', 'example,', 'but', 'hopefully', 'I', 'made', 'my', 'point-', \"it's\", 'all', 'a', 'matter', 'of', 'perception,', 'and', 'as', 'long', 'as', 'someone', 'ingesting', 'MSG', 'perceives', 'it', 'as', 'causing', 'bad', 'effects,', 'then', 's/he', 'can', 'definitely', 'experience', 'those', 'affects.', 'On', 'the', 'other', 'hand,', 'it', 'could', 'just', 'be', 'an', 'allergy', 'to', 'the', 'food', \"it's\", 'in,', 'or', 'something.', 'Still,', 'anecdotal', 'evidence', 'is', 'not', 'worthless-', \"it's\", 'the', 'stuff', 'that', 'leads', 'to', 'the', 'study', 'being', 'done.', '-Dan'], tags=['Train_0']),\n",
       " TaggedDocument(words=['From:', 'yoo@engr.ucf.edu', '(Hoi', 'Yoo)', 'Subject:', 'looking', 'for', 'USA', 'map', 'Organization:', 'engineering,', 'University', 'of', 'Central', 'Florida,', 'Orlando', 'Lines:', '11', 'Does', 'anyone', 'out', 'there', 'have', 'or', 'know', 'of,', 'line', 'drawing', 'USA', 'map?', 'Thanks', 'very', 'much', 'in', 'advance,', 'Hoi', 'yoo@engr.ucf.edu'], tags=['Train_1'])]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3759/3759 [00:00<00:00, 1255785.64it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3759/3759 [00:00<00:00, 1255085.87it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1821861.42it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1677810.87it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1847912.42it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 3780908.57it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1885480.60it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1891815.30it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 846790.31it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 3770059.48it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1886157.28it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1255785.64it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1238619.59it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1883678.46it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 823611.18it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1255985.72it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1860560.39it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1882778.69it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 2022109.62it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1483057.92it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1633822.67it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1258793.51it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 2117146.33it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 3768257.35it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1883678.46it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1456479.33it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 942345.87it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1882104.42it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 3777285.27it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1256987.06it/s]\n",
      "100%|██████████| 3759/3759 [00:00<00:00, 1883678.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data1)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train1), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test1), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abishek\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\abishek\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=1, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, news_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abishek\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\abishek\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = logreg.fit(train_vectors_dbow, news_train.target)\n",
    "y_pred = logreg.predict(test_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8641810918774967\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.84      0.80      0.82       319\n",
      "soc.religion.christian       0.86      0.93      0.89       389\n",
      "         comp.graphics       0.91      0.85      0.88       396\n",
      "               sci.med       0.84      0.87      0.85       398\n",
      "\n",
      "              accuracy                           0.86      1502\n",
      "             macro avg       0.86      0.86      0.86      1502\n",
      "          weighted avg       0.87      0.86      0.86      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, news_test.target))\n",
    "print(classification_report(news_test.target, y_pred,target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(train_vectors_dbow, news_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8468708388814914\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.84      0.75      0.79       319\n",
      "soc.religion.christian       0.89      0.90      0.90       389\n",
      "         comp.graphics       0.88      0.83      0.85       396\n",
      "               sci.med       0.79      0.89      0.84       398\n",
      "\n",
      "              accuracy                           0.85      1502\n",
      "             macro avg       0.85      0.84      0.84      1502\n",
      "          weighted avg       0.85      0.85      0.85      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, news_test.target))\n",
    "print(classification_report(news_test.target, y_pred,target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction-   bag of words==> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train['post']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(x_train,news_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test['post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8708388814913449\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.99      0.65      0.78       319\n",
      "soc.religion.christian       0.96      0.94      0.95       389\n",
      "         comp.graphics       0.95      0.87      0.91       396\n",
      "               sci.med       0.71      0.98      0.83       398\n",
      "\n",
      "              accuracy                           0.87      1502\n",
      "             macro avg       0.90      0.86      0.87      1502\n",
      "          weighted avg       0.90      0.87      0.87      1502\n",
      "\n",
      "Wall time: 429 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, news_test.target))\n",
    "print(classification_report(news_test.target, y_pred,target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('model', XGBClassifier()),\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=100, n_jobs=1, nthread=None,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(x_train,news_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8149134487350199\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.92      0.69      0.79       319\n",
      "soc.religion.christian       0.74      0.93      0.82       389\n",
      "         comp.graphics       0.79      0.79      0.79       396\n",
      "               sci.med       0.86      0.83      0.85       398\n",
      "\n",
      "              accuracy                           0.81      1502\n",
      "             macro avg       0.83      0.81      0.81      1502\n",
      "          weighted avg       0.83      0.81      0.81      1502\n",
      "\n",
      "Wall time: 467 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, news_test.target))\n",
    "print(classification_report(news_test.target, y_pred,target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert(string): \n",
    "    li = list(string.split(\",\")) \n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter newsThe graphics card improved a lot in these days\n"
     ]
    }
   ],
   "source": [
    "stringinput=input(\"enter news\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "news=Convert(stringinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "news=pd.DataFrame(news,columns=['news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_pred=news['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(news_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-alt.aetheism\n",
    "1-comp.graphics\n",
    "2-sci.med\n",
    "3-soc.religion.christian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
